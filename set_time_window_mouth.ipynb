{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyproj\n",
    "from  pyproj  import  CRS\n",
    "from pyproj import Proj\n",
    "import h5py\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import cm, colors\n",
    "import glob\n",
    "from mpl_toolkits.basemap import BasemapW\n",
    "from netCDF4 import Dataset\n",
    "import pandas as pd\n",
    "import gzip\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置空间分辨率\n",
    "resolution = 10000\n",
    "\n",
    "# 将WGS 84坐标（4326）转化为等距圆柱投影（4088）\n",
    "crs = CRS.from_epsg(4326)\n",
    "crs = CRS.from_string(\"epsg:4326\")\n",
    "crs = CRS.from_proj4(\"+proj=latlon\")\n",
    "crs = CRS.from_user_input(4326)\n",
    "crs2 = CRS.from_epsg(4088)\n",
    "crs2 = CRS.from_string(\"epsg:4088\")\n",
    "crs2 = CRS.from_proj4(\"+proj=latlon\")\n",
    "crs2 = CRS.from_user_input(4088)\n",
    "\n",
    "transformer = pyproj.Transformer.from_crs(crs,crs2)\n",
    "transformer_back = pyproj.Transformer.from_crs(crs2,crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取数组的长和宽\n",
    "def get_nlat_nlon_npaeqd(resolution):\n",
    "    nlat, nlon =40000000/ resolution,40000000/ resolution\n",
    "    nlat = np.int(nlat)\n",
    "    nlon = np.int(nlon)\n",
    "    return nlat, nlon\n",
    "    \n",
    "    \n",
    "def get_nlat_nlon_cyl(resolution):\n",
    "    nlat, nlon =40000000/ resolution,20000000/ resolution\n",
    "    nlat = np.int(nlat)\n",
    "    nlon = np.int(nlon)\n",
    "    return nlat, nlon\n",
    "\n",
    "# 获取用来存放数据的grid数组，及其对应的grid_num数组（用来存放一个格子中有多少重合点），以及对应的初始time数组\n",
    "def get_swh_grid(nlat, nlon):\n",
    "    swh_grid = np.full(shape=(nlon,nlat), fill_value=np.nan)\n",
    "    swh_grid_num = np.zeros((nlon,nlat))\n",
    "    swh_grid_time = np.full(shape=(nlon,nlat), fill_value=np.nan)\n",
    "    return swh_grid, swh_grid_num, swh_grid_time\n",
    "\n",
    "def get_num_grid(nlat, nlon):\n",
    "    num_grid = np.zeros((nlon,nlat))\n",
    "    return num_grid\n",
    "\n",
    "# 填充每个点的数值，将有重复数据的点标记到swh_grid_num中,最后求平均\n",
    "def coincident_point_mean(value_array, grid_array, grid_num_array, projlats, projlons):\n",
    "    for i in range(len(value_array)):\n",
    "        x = int((projlons[i] )/resolution)\n",
    "        y = int(projlats[i]/resolution)\n",
    "        if grid_num_array[x][y] == 0:\n",
    "            grid_array[x][y] = value_array[i]\n",
    "            grid_num_array[x][y] += 1\n",
    "        else:\n",
    "            grid_array[x][y] += value_array[i]\n",
    "            grid_num_array[x][y] += 1\n",
    "    grid_array = grid_array / grid_num_array\n",
    "    return grid_array\n",
    "\n",
    "# def coincident_time_log(value_array, grid_array, grid_num_array, grid_time_array, projlats, projlons):\n",
    "#     time_dict = {}\n",
    "#     for i in range(len(value_array)):\n",
    "#         x = int((projlons[i] )/resolution)\n",
    "#         y = int(projlats[i]/resolution)\n",
    "#         if grid_num_array[x][y] == 0:\n",
    "#             hy_grid[x][y] = hy_value_array_masked[i]\n",
    "#             hy_time_grid[x][y] = hy_time_array[i]\n",
    "#             dict_name = str(x) + '+' + str(y)\n",
    "#             hy_time_dict[dict_name] = {hy_time_grid[x][y]: hy_grid[x][y]}\n",
    "#             grid_num_array[x][y] = 1\n",
    "        \n",
    "#         else:\n",
    "#             dict_name = str(x) + '+' + str(y)\n",
    "#             hy_time_dict[dict_name][hy_time_array[i]] = hy_value_array_masked[i]\n",
    "#             grid_num_array[x][y] += 1\n",
    "        \n",
    "#     # 删除没有重合点的子字典\n",
    "#     for key in list(hy_time_dict.keys()):\n",
    "#         if len(hy_time_dict[key].items()) < 2 :\n",
    "#             del hy_time_dict[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理hy数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2019\n",
    "month = 8\n",
    "\n",
    "save_output_path = r'.\\output\\month\\2019\\05'\n",
    "hy_dir_path = r'G:\\remote_sensing_data\\HY-2B\\2019\\05'\n",
    "# hy_dir_path_01 = r'G:\\remote_sensing_data\\HY-2B\\2020\\07\\20200701_20200711\\20200711'\n",
    "hyfiles = glob.glob(hy_dir_path + '\\*.nc')\n",
    "hy_lon_array = np.array([])\n",
    "hy_lat_array = np.array([])\n",
    "hy_time_array = np.array([])\n",
    "hy_value_array = np.array([])\n",
    "hy_swhc_mask_array = np.array([])\n",
    "\n",
    "for hyfile in hyfiles:\n",
    "    with Dataset(hyfile, mode='r') as fh:\n",
    "        lons = fh.variables['lon'][:]\n",
    "        lats = fh.variables['lat'][:]\n",
    "        swhc = fh.variables['swh_c'][:]\n",
    "        time = fh.variables['time'][:]\n",
    "        swhc_mask = swhc.mask\n",
    "        hy_lon_array = np.append(hy_lon_array, lons)\n",
    "        hy_lat_array = np.append(hy_lat_array, lats)\n",
    "        hy_value_array = np.append(hy_value_array, swhc)\n",
    "        hy_time_array = np.append(hy_time_array, time)\n",
    "        hy_swhc_mask_array = np.append(hy_swhc_mask_array, swhc_mask)\n",
    "    hy_value_array_masked = np.ma.array(hy_value_array, mask=hy_swhc_mask_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hy_df = pd.DataFrame([hy_lon_array, hy_lat_array, hy_time_array, hy_value_array_masked], index=['lon', 'lat', 'time', 'swh'])\n",
    "hy_df.to_csv(save_output_path + '\\\\' + 'hy_df_swh.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hy_projlats,hy_projlons = transformer.transform(hy_lat_array,hy_lon_array)\n",
    "# 获取东西半球的nlat，nlon，is_grid_west,is_grid_num_west\n",
    "hy_nlat, hy_nlon =get_nlat_nlon_cyl(resolution)\n",
    "hy_grid, hy_num_grip, hy_time_grid = get_swh_grid(hy_nlat*2, hy_nlon*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-634cf2e4aca7>:6: UserWarning: Warning: converting a masked element to nan.\n",
      "  hy_grid[x][y] = hy_value_array_masked[i]\n"
     ]
    }
   ],
   "source": [
    "hy_time_dict = {}\n",
    "for i in range(len(hy_value_array_masked)):\n",
    "    x = int((hy_projlons[i] )/resolution)\n",
    "    y = int(hy_projlats[i]/resolution)\n",
    "    if hy_num_grip[x][y] == 0:\n",
    "        hy_grid[x][y] = hy_value_array_masked[i]\n",
    "        hy_time_grid[x][y] = hy_time_array[i]\n",
    "        dict_name = str(x) + '+' + str(y)\n",
    "        hy_time_dict[dict_name] = {hy_time_grid[x][y]: hy_grid[x][y]}\n",
    "        hy_num_grip[x][y] = 1\n",
    "        \n",
    "    else:\n",
    "        dict_name = str(x) + '+' + str(y)\n",
    "        hy_time_dict[dict_name][hy_time_array[i]] = hy_value_array_masked[i]\n",
    "        hy_num_grip[x][y] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-3b7e03c2948e>:32: UserWarning: Warning: converting a masked element to nan.\n",
      "  grid_array[x][y] = value_array[i]\n",
      "<ipython-input-3-3b7e03c2948e>:35: UserWarning: Warning: converting a masked element to nan.\n",
      "  grid_array[x][y] += value_array[i]\n"
     ]
    }
   ],
   "source": [
    "# 获取东西半球的nlat，nlon，is_grid_west,is_grid_num_west\n",
    "_, hy_mean_num_grip, _ = get_swh_grid(hy_nlat*2, hy_nlon*2)\n",
    "\n",
    "# 交叉点平均化\n",
    "hy_mean_grid = coincident_point_mean(hy_value_array_masked, hy_grid, hy_mean_num_grip, hy_projlats,hy_projlons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cryosat 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cy_dir_path = r'G:\\remote_sensing_data\\CRYOSAT-2\\2019\\05'\n",
    "# cy_dir_path_01 = r\"G:\\remote_sensing_data\\CRYOSAT-2\\2020\\07\\20200711\"\n",
    "cyfiles = glob.glob(cy_dir_path + '\\*.nc')\n",
    "cy_lon_array = np.array([])\n",
    "cy_lat_array = np.array([])\n",
    "cy_swh_array = np.array([])\n",
    "cy_swh_mask_array = np.array([])\n",
    "cy_time_array = np.array([])\n",
    "\n",
    "for cyfile in cyfiles:\n",
    "    with Dataset(cyfile, mode='r') as fh:\n",
    "        lons = fh.variables['lon_01'][:]\n",
    "        lats = fh.variables['lat_01'][:]\n",
    "        swh = fh.variables['swh_ocean_01_ku'][:]\n",
    "        time = fh.variables['time_cor_01'][:]\n",
    "        swh_mask = swh.mask\n",
    "        if np.array(swh_mask,dtype = bool).shape == ():\n",
    "            swh_mask = np.full((len(swh), ), False)\n",
    "        cy_lon_array = np.append(cy_lon_array, lons)\n",
    "        cy_lat_array = np.append(cy_lat_array, lats)\n",
    "        cy_swh_array = np.append(cy_swh_array, swh)\n",
    "        cy_swh_mask_array = np.append(cy_swh_mask_array, swh_mask)\n",
    "        cy_time_array = np.append(cy_time_array, time)\n",
    "cy_swh_array_masked = np.ma.array(cy_swh_array, mask=cy_swh_mask_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cy_df = pd.DataFrame([cy_lon_array, cy_lat_array, cy_time_array, cy_swh_array_masked], index=['lon', 'lat', 'time', 'swh'])\n",
    "cy_df.to_csv(save_output_path + '\\\\' + 'cy_df_swh.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cy_lower_index = []\\nfor i in range(len(cy_swh_array_masked)):\\n    if cy_lat_array[i] > 60 or cy_lat_array[i] < -60:\\n        cy_lower_index.append(i)\\n\\ncy_lat_array = np.delete(cy_lat_array, cy_lower_index)\\ncy_lon_array = np.delete(cy_lon_array, cy_lower_index)\\ncy_swh_array = np.delete(cy_swh_array, cy_lower_index)\\ncy_swh_mask_array = np.delete(cy_swh_mask_array, cy_lower_index)\\ncy_swh_array_masked = np.ma.array(cy_swh_array, mask=cy_swh_mask_array)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''cy_lower_index = []\n",
    "for i in range(len(cy_swh_array_masked)):\n",
    "    if cy_lat_array[i] > 60 or cy_lat_array[i] < -60:\n",
    "        cy_lower_index.append(i)\n",
    "\n",
    "cy_lat_array = np.delete(cy_lat_array, cy_lower_index)\n",
    "cy_lon_array = np.delete(cy_lon_array, cy_lower_index)\n",
    "cy_swh_array = np.delete(cy_swh_array, cy_lower_index)\n",
    "cy_swh_mask_array = np.delete(cy_swh_mask_array, cy_lower_index)\n",
    "cy_swh_array_masked = np.ma.array(cy_swh_array, mask=cy_swh_mask_array)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cy_projlats,cy_projlons = transformer.transform(cy_lat_array,cy_lon_array)\n",
    "\n",
    "# 获取东西半球的nlat，nlon，cy_grid_west,cy_grid_num_west\n",
    "cy_nlat, cy_nlon =get_nlat_nlon_cyl(resolution)\n",
    "cy_grid, cy_num_grip, cy_time_grid = get_swh_grid(cy_nlat*2, cy_nlon*2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-893a831ee7fa>:6: UserWarning: Warning: converting a masked element to nan.\n",
      "  cy_grid[x][y] = cy_swh_array_masked[i]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# 删除没有重合点的子字典\\nfor key in list(cy_time_dict.keys()):\\n    if len(cy_time_dict[key].items()) < 2 :\\n        del cy_time_dict[key]'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cy_time_dict = {}\n",
    "for i in range(len(cy_swh_array_masked)):\n",
    "    x = int((cy_projlons[i] )/resolution)\n",
    "    y = int(cy_projlats[i]/resolution)\n",
    "    if cy_num_grip[x][y] == 0:\n",
    "        cy_grid[x][y] = cy_swh_array_masked[i]\n",
    "        cy_time_grid[x][y] = cy_time_array[i]\n",
    "        dict_name = str(x) + '+' + str(y)\n",
    "        cy_time_dict[dict_name] = {cy_time_grid[x][y]: cy_grid[x][y]}\n",
    "        cy_num_grip[x][y] = 1\n",
    "        \n",
    "    else:\n",
    "        dict_name = str(x) + '+' + str(y)\n",
    "        cy_time_dict[dict_name][cy_time_array[i]] = cy_swh_array_masked[i]\n",
    "        cy_num_grip[x][y] += 1\n",
    "'''\n",
    "# 删除没有重合点的子字典\n",
    "for key in list(cy_time_dict.keys()):\n",
    "    if len(cy_time_dict[key].items()) < 2 :\n",
    "        del cy_time_dict[key]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-3b7e03c2948e>:32: UserWarning: Warning: converting a masked element to nan.\n",
      "  grid_array[x][y] = value_array[i]\n",
      "<ipython-input-3-3b7e03c2948e>:35: UserWarning: Warning: converting a masked element to nan.\n",
      "  grid_array[x][y] += value_array[i]\n"
     ]
    }
   ],
   "source": [
    "_, cy_mean_num_grip, _ = get_swh_grid(cy_nlat*2, cy_nlon*2)\n",
    "\n",
    "# 交叉点平均化\n",
    "cy_mean_grid = coincident_point_mean(cy_swh_array_masked, cy_grid, cy_mean_num_grip, cy_projlats,cy_projlons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理icesat数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# icesat2 的时间是从2018-01-01 00：00：00开始记的，Hy2b和cryosat2的是从2000-01-01 00：00：00开始计的\n",
    "# 2018-01-01 00：00：00 与2000-01-01 00：00：00 相差了568080000秒\n",
    "correction_second = 568080000\n",
    "\n",
    "\n",
    "dir_path_01 = r'G:\\remote_sensing_data\\ICESAT-2\\2019\\05'\n",
    "ncfiles = glob.glob(dir_path_01 + '\\*.h5')\n",
    "is_lon_array = np.array([])\n",
    "is_lat_array = np.array([])\n",
    "is_value_array = np.array([])\n",
    "is_time_array = np.array([])\n",
    "tracks = ['gt1l','gt1r','gt2l','gt2r','gt3l','gt3r']\n",
    "# tracks = ['gt1l','gt2l','gt2r','gt3l','gt3r']\n",
    "for ncfile in ncfiles:\n",
    "    with h5py.File(ncfile, 'r') as f:\n",
    "        for track in tracks:\n",
    "            try: \n",
    "                lats = f[track]['ssh_segments']['latitude'][:]\n",
    "                lons = f[track]['ssh_segments']['longitude'][:]\n",
    "                value = f[track]['ssh_segments']['heights']['swh'][:]\n",
    "                time = f[track]['ssh_segments']['delta_time'][:]\n",
    "            \n",
    "                is_lon_array = np.append(is_lon_array, lons)\n",
    "                is_lat_array = np.append(is_lat_array, lats)\n",
    "                is_value_array = np.append(is_value_array, value)\n",
    "                is_time_array = np.append(is_time_array, time + correction_second)\n",
    "            except KeyError:\n",
    "                print(ncfile,track)\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_df = pd.DataFrame([is_lon_array, is_lat_array, is_time_array, is_value_array], index=['lon', 'lat', 'time', 'swh'])\n",
    "is_df.to_csv(save_output_path + '\\\\' + 'is_df_swh.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_projlats,is_projlons = transformer.transform(is_lat_array,is_lon_array)\n",
    "\n",
    "# 获取东西半球的nlat，nlon，is_grid_west,is_grid_num_west\n",
    "is_nlat, is_nlon =get_nlat_nlon_cyl(resolution)\n",
    "is_grid, is_num_grip, is_time_grid = get_swh_grid(is_nlat*2, is_nlon*2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_time_dict = {}\n",
    "n=1\n",
    "for i in range(len(is_value_array)):\n",
    "    x = int((is_projlons[i] )/resolution)\n",
    "    y = int(is_projlats[i]/resolution)\n",
    "    if is_num_grip[x][y] == 0:\n",
    "        is_grid[x][y] = is_value_array[i]\n",
    "        is_time_grid[x][y] = is_time_array[i]\n",
    "        dict_name = str(x) + '+' + str(y)\n",
    "        is_time_dict[dict_name] = {is_time_grid[x][y]: is_grid[x][y]}\n",
    "        is_num_grip[x][y] = 1\n",
    "            \n",
    "    else:\n",
    "        dict_name = str(x) + '+' + str(y)\n",
    "        is_time_dict[dict_name][is_time_array[i]] = is_value_array[i]\n",
    "        is_num_grip[x][y] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, is_mean_num_grip, _ = get_swh_grid(is_nlat*2, is_nlon*2)\n",
    "\n",
    "# 交叉点平均化\n",
    "is_mean_grid = coincident_point_mean(is_value_array, is_grid, is_mean_num_grip, is_projlats,is_projlons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 存储中间文件，数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(save_output_path +'\\\\'+'hy_mean_grid' ,hy_mean_grid)\n",
    "np.save(save_output_path +'\\\\'+'hy_mean_num_grip' ,hy_mean_num_grip)\n",
    "\n",
    "# np.save(save_output_path +'\\\\'+'cy_mean_grid' ,cy_mean_grid)\n",
    "# np.save(save_output_path +'\\\\'+'cy_mean_num_grip' ,cy_mean_num_grip)\n",
    "\n",
    "\n",
    "np.save(save_output_path +'\\\\'+'is_mean_grid' ,is_mean_grid)\n",
    "np.save(save_output_path +'\\\\'+'is_mean_num_grip' ,is_mean_num_grip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 设置时间窗口为3600秒\n",
    "time_window = 3600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对比hy与cryosat交叉点\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cy_mean_grid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-95ffc92e9d4d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 将两个grid数组相减，还有数据的部分为交叉点\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhy_cy_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhy_mean_grid\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mcy_mean_grid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mhy_cy_diff_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhy_cy_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m!=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# 设置时间窗口为3600秒\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cy_mean_grid' is not defined"
     ]
    }
   ],
   "source": [
    "# 将两个grid数组相减，还有数据的部分为交叉点\n",
    "hy_cy_grid = hy_mean_grid - cy_mean_grid\n",
    "hy_cy_diff_grid = np.argwhere(np.isnan(hy_cy_grid)!= True)\n",
    "\n",
    "\n",
    "# 创建一个用来存储点对的list\n",
    "hy_cy_coincident_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for cy_time_key in cy_time_dict['-607+-1611'].keys():\n",
    "    print(cy_time_key)\n",
    "    print(cy_time_dict['-607+-1611'][cy_time_key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cy_time_dict['-607+-1611']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(hy_cy_diff_grid)): \n",
    "    diff_x = hy_cy_diff_grid[i][0]\n",
    "    if diff_x > 2000: diff_x -= 4000\n",
    "    diff_y = hy_cy_diff_grid[i][1]\n",
    "    if diff_y > 4000: diff_y -= 8000\n",
    "    key = str(diff_x) + '+' + str(diff_y)\n",
    "    \n",
    "    for cy_time_key in cy_time_dict[key].keys():\n",
    "        for hy_time_key in hy_time_dict[key].keys():\n",
    "            if np.abs(hy_time_key - cy_time_key)< time_window :\n",
    "                coincident_value = []\n",
    "                coincident_value.append(key)\n",
    "                coincident_value.append(hy_time_key)\n",
    "                coincident_value.append(hy_time_dict[key][hy_time_key])\n",
    "                coincident_value.append(cy_time_key)\n",
    "                coincident_value.append(cy_time_dict[key][cy_time_key])\n",
    "                hy_cy_coincident_list.append(coincident_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1352"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 输出符合条件的点\n",
    "len(hy_cy_coincident_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hy_overlap_swh = np.array([])\\ncy_overlap_swh = np.array([])\\ndiff_value = np.array([])\\nfor i in range(len(hy_cy_diff_grid)):\\n    hy_overlap_swh = np.append(hy_overlap_swh, hy_grid[hy_cy_diff_grid[i][0], hy_cy_diff_grid[i][1]])\\n    cy_overlap_swh = np.append(cy_overlap_swh, cy_grid[hy_cy_diff_grid[i][0], hy_cy_diff_grid[i][1]])\\n    diff_value = np.append(diff_value, round(hy_cy_grid[hy_cy_diff_grid[i][0], hy_cy_diff_grid[i][1]], 8))\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''hy_overlap_swh = np.array([])\n",
    "cy_overlap_swh = np.array([])\n",
    "diff_value = np.array([])\n",
    "for i in range(len(hy_cy_diff_grid)):\n",
    "    hy_overlap_swh = np.append(hy_overlap_swh, hy_grid[hy_cy_diff_grid[i][0], hy_cy_diff_grid[i][1]])\n",
    "    cy_overlap_swh = np.append(cy_overlap_swh, cy_grid[hy_cy_diff_grid[i][0], hy_cy_diff_grid[i][1]])\n",
    "    diff_value = np.append(diff_value, round(hy_cy_grid[hy_cy_diff_grid[i][0], hy_cy_diff_grid[i][1]], 8))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# 将每个交叉点的数值记入DataFrame\\n\\nhy_cy_data={'HY-2B swh':hy_overlap_swh,\\n      'CRYOSAT swh':cy_overlap_swh,\\n      'Diff':diff_value\\n     }\\nhy_cy_df = pd.DataFrame(hy_cy_data)\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# 将每个交叉点的数值记入DataFrame\n",
    "\n",
    "hy_cy_data={'HY-2B swh':hy_overlap_swh,\n",
    "      'CRYOSAT swh':cy_overlap_swh,\n",
    "      'Diff':diff_value\n",
    "     }\n",
    "hy_cy_df = pd.DataFrame(hy_cy_data)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对比hy与icesat交叉点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将两个grid数组相减，还有数据的部分为交叉点\n",
    "hy_is_grid = hy_mean_grid - is_mean_grid\n",
    "hy_is_diff_grid = np.argwhere(np.isnan(hy_is_grid)!= True)\n",
    "\n",
    "\n",
    "# 创建一个用来存储点对的list\n",
    "hy_is_coincident_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(hy_is_diff_grid)): \n",
    "    diff_x = hy_is_diff_grid[i][0]\n",
    "    if diff_x > 2000: diff_x -= 4000\n",
    "    diff_y = hy_is_diff_grid[i][1]\n",
    "    if diff_y > 4000: diff_y -= 8000\n",
    "    key = str(diff_x) + '+' + str(diff_y)\n",
    "    \n",
    "    for is_time_key in is_time_dict[key].keys():\n",
    "        for hy_time_key in hy_time_dict[key].keys():\n",
    "            if np.abs(hy_time_key - is_time_key)< time_window :\n",
    "                coincident_value = []\n",
    "                coincident_value.append(key)\n",
    "                coincident_value.append(hy_time_key)\n",
    "                coincident_value.append(hy_time_dict[key][hy_time_key])\n",
    "                coincident_value.append(is_time_key)\n",
    "                coincident_value.append(is_time_dict[key][is_time_key])\n",
    "                hy_is_coincident_list.append(coincident_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10622"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 输出符合条件的点\n",
    "len(hy_is_coincident_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
